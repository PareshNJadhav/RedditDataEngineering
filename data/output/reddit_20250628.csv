id,title,score,num_comments,author,selftext,created_utc,url,over_18,edited,spoiler,stickied
1llt6y9,"Do you use CDC? If yes, how does it benefit you?",57,81,wtfzambo,"I am dealing with a data pipeline that uses CDC on pretty much all DB tables.
The changes are written to object storage, and daily merged to a Delta table using SCD2 strategy. One Delta for each DB table.

After working with this for a few months, I have concluded that, most likely, the project would be better off if we just switched to daily full snapshots, getting rid of both CDC and SCD2.

Which then led me to the above question in the title: did you ever find yourself in a situation were CDC was the optimal solution? If so, can you elaborate? How was CDC data modeled afterwards?

Thanks in advance for your contribution!",2025-06-27 12:56:16,https://www.reddit.com/r/dataengineering/comments/1llt6y9/do_you_use_cdc_if_yes_how_does_it_benefit_you/,False,False,False,False
1lm5zle,What is happening in the Swedish job market right now?,26,17,BadBouncyBear,"I noticed a big upswing in recruitment the last couple of months. I changed job for a big pay increase 3 months ago, and next month I will change job again for another big pay increase. I have 1.5 years of experience and I'm going to get paid like someone with 10 years of experience in Sweden. It feels like they are trying to get anyone who has watched a 10 minute video about Databricks",2025-06-27 21:43:18,https://www.reddit.com/r/dataengineering/comments/1lm5zle/what_is_happening_in_the_swedish_job_market_right/,False,False,False,False
1llv0oe,Data Engineer or Software Engineer - Data,23,19,eastieLad,"Obviously titles are not that important in the grand scheme of things, however, I might have the option between titles. Which do you think is more favorable Data Engineer or Software Engineer - Data?",2025-06-27 14:16:40,https://www.reddit.com/r/dataengineering/comments/1llv0oe/data_engineer_or_software_engineer_data/,False,False,False,False
1llvqzs,Would you take a $27K pay cut to land your first DE role?,16,57,Miserable-Toe5090,"Hey everyone‚ÄîI could really use some advice.

I‚Äôm currently a senior data analyst working in healthcare fraud analytics and model development at a large government contracting firm. Our client has multiple contracts with us, and I support one of them. I‚Äôve been interested in moving into data engineering for a while and am about halfway through a master‚Äôs in computer and information technology.

Recently, I asked if I could shadow the DE team on an adjacent contract, and they brought me in for their latest sprint. Shortly after, the program manager on that team asked if I‚Äôd be interested in applying for an open DE role. I was thrilled‚Äîit felt like the perfect opportunity.

I already know the data really well (I worked on their recent migration efforts and use their tables regularly), and I‚Äôm familiar with some of the team. It‚Äôs a solid internal move with a lot of alignment.

The catch? I‚Äôd have to take a $27K pay cut‚Äîfrom $137K to $110K.
I expected a cut since I don‚Äôt have formal DE experience and would be stepping into a mid-level role, but that number feels steep‚Äîespecially since I live in a high cost of living area and recently bought a house.

‚∏ª

My question for you all:
1. Would you take the job anyway, just to get your foot in the door?
2. Has anyone else here made a similar internal switch from analyst to DE? How did it work out long-term?
3. Are there ways to negotiate this kind of internal transition to ease the pay gap? (e.g. retention bonus, hybrid role, defined promotion path)
4. If I pass this up, how hard would it be to break into DE externally without prior experience or the DE title?

Any perspective‚Äîespecially from folks who‚Äôve made the jump or hired junior/mid DEs‚Äîwould really help. Thanks in advance!",2025-06-27 14:47:15,https://www.reddit.com/r/dataengineering/comments/1llvqzs/would_you_take_a_27k_pay_cut_to_land_your_first/,False,False,False,False
1lm96a5,Comparison of modern CDC tools Debezium vs Estuary Flow,16,2,subhanhg,Inspired by the recent discussions around CDC I have written in depth article about modern CDC tools.,2025-06-28 00:06:33,https://dataheimer.substack.com/p/the-ultimate-guide-to-change-data,False,False,False,False
1llngh8,How to debug dbt SQL?,12,30,backend-dev,"With dbt incremental models, dbt uses your model SQL to create to temp table from where it does a merge. You don‚Äôt seem to be able to access this sql in order to view or debug it. This is incredibly frustrating and unproductive. My models use a lot of macros and the tweak macro / run cycle eats time. Any suggestions?",2025-06-27 07:03:38,https://www.reddit.com/r/dataengineering/comments/1llngh8/how_to_debug_dbt_sql/,False,False,False,False
1lm5s13,Prefect Self-Hosted Server?,7,3,mild_convective_strm,Has anybody here gone the route of a self-hosted Prefect server rather than Prefect Cloud? Can you actually run the server version on Windows? I tried l looking through the documentation and it mentioned running on Linux and Docker but not much else from what I could find.,2025-06-27 21:34:16,https://www.reddit.com/r/dataengineering/comments/1lm5s13/prefect_selfhosted_server/,False,False,False,False
1lmaqrx,Wanting to copy csv files from SharePoint to Azure Blob storage,7,0,RobDoesData,"I'm trying to copy files from a SharePoint folder to ADLS (initially just by pointing at a folder but eventually do something to look for changed files). Naturally I thought to use Data Factory but it seems the docs are out of date. 

Anyone have a successful guide or link that works in 2025?",2025-06-28 01:25:57,https://www.reddit.com/r/dataengineering/comments/1lmaqrx/wanting_to_copy_csv_files_from_sharepoint_to/,False,False,False,False
1lm7j6u,Fast spatial query db?,6,11,InternationalMany6,"I've got a large collection of points of interest (GPS latitude and longitude) to store and am looking for a good in-process OLAP database to store and query them from, which supports spatial indexes and ideally out-of-core storage and Python on Windows support.

Something like DuckDB with their spatial extension would work, but do people have any other suggestions?

An illustrative use case is this: the db stores the location of every house in a country along with a few attribute like household income and number of occupants. (Don't worry that's not actually what I'm storing, but it's comparable in scope). A typical query is to get the total occupants within a quarter mile of every house in a certain state. So I can say that 123 Main Street has 100 people living nearby....repeated for 100,000 other addresses. 
",2025-06-27 22:50:14,https://www.reddit.com/r/dataengineering/comments/1lm7j6u/fast_spatial_query_db/,False,False,False,False
1llrd1d,Where do you store static element you need to?,6,5,Commercial_Dig2401,"I was wondering where do you usually store static element that are often require to ingest or to filter in your different pipeline.

Currently we use DBT seeds, for most of them, this remove static elements from our SQL files but CSV seeds are often not enough to represent the static element I require.

For example, one of my third party vendors have an endpoint which return a bunch of data in a lot of different format, I would like to track a list of the format I‚Äôve approved, validated, etc.
The different type of data are generally handle by 2 elements. I would like to avoid having to define element1, subelement1, approved, format_x

element1, subelement2, approved, format_y.

I currently can do this in seeds but what I would like is a kind of CRM that allow me to do relations. So if element1 is approve than that‚Äôs something, and I have somewhere else to store all approved subelement for this.

Might be complicate to understand in simple words, but tldr how do you store static things that are required for your pipeline ? I want something else than juste a table in Postgres because I want non tech people to be able to add elements

We currently use Salesforce for some stuff, but are going away from it so I try to find a simple solution which can work for DE and not necessary the company as a hole. Something simple nothing fancy is required.

Thanks",2025-06-27 11:21:09,https://www.reddit.com/r/dataengineering/comments/1llrd1d/where_do_you_store_static_element_you_need_to/,False,False,False,False
1lm44es,Best way to schedule python job in azure,6,6,boogie_woogie_100,"So, we are using Azure with snowflake and I want to schedule a python program which does some admin work and need to schedule it and write the data into snowflake table. What would be the best way to schedule it? I am not going to run it everyday, probably once per quarter.  I was thinking to azure runbook. My python package requires some packages such as azure identity and snowflake connector for python but it really doesn't work well with runbook and have so many restriction.  What could be other options?  
",2025-06-27 20:23:55,https://www.reddit.com/r/dataengineering/comments/1lm44es/best_way_to_schedule_python_job_in_azure/,False,False,False,False
1lm69l1,When did conda-forge start to carry PySpark,5,0,MereRedditUser,"Being a math modeller instead of a computers scientist, I found the process of connecting Anaconda Python to PySpark to be extremely painful and time consuming.  Each time I had to do this on another computer.

Just now, I found that conda-forge carries PySpark.  I wonder how long it has been available, and hence, whether I could have avoided the ordeals in getting PySpark working (and not very well, at that).

Looking back at the files [here](https://anaconda.org/conda-forge/pyspark/files), it seems that it started 8 years ago, which is much longer than I've been using Python, and much, much longer than my stints into PySpark.  Is this a reasonably accurate way to determine how long it has been available?",2025-06-27 21:55:05,https://www.reddit.com/r/dataengineering/comments/1lm69l1/when_did_condaforge_start_to_carry_pyspark/,False,False,False,False
1llsfls,Azure DevOps & MYSQL,4,0,Status-Locksmith5158,"Not sure if this is the correct forum, so apologises.
Am from a SQL Server background and using CI/CD is pretty straight forward with DACPACs and pipelines.  Was wondering if anyone had any advice/experiences doing CI/CD pipelines for MYSQL ?
Am trying to use Flyway, but it looks like their is a fair bit of manual intervention generating scripts for deployment.
Is this the best way I have to achieve deployments or is this a bonkers old antiquated way of doing this ?
Please feel free to shoot this down.  Any advice very much appreciated üëè 
Thanks people ü•≥",2025-06-27 12:19:14,https://www.reddit.com/r/dataengineering/comments/1llsfls/azure_devops_mysql/,False,False,False,False
1llxkem,Interesting links - June 2025,3,0,rmoff,,2025-06-27 16:00:22,https://rmoff.net/2025/06/27/interesting-links-june-2025/,False,False,False,False
1llnzqm,[Academic][Survey] DevOps Practices and Software Quality,3,0,wczp,"Hi everyone,  
I am a master's student in Project Management at WSB Merito University in Toru≈Ñ, Poland. As part of my thesis, I am conducting a survey on how DevOps practices affect the quality of software delivery in IT organizations.

If you work in software development, DevOps, QA, infrastructure, or any IT-related area and have experience with DevOps practices, your input would be greatly appreciated.

The survey consists of 16 questions and takes approximately 10 minutes to complete. All responses are anonymous and will be used solely for academic purposes.

[**Survey Link**](https://docs.google.com/forms/d/e/1FAIpQLSdE5v6EEz5LsvK_13QsTkgkyxJRmAp1Ws2Vx2SdvZHZm65PJA/viewform?usp=dialog)

Thank you for your time and support!",2025-06-27 07:40:16,https://www.reddit.com/r/dataengineering/comments/1llnzqm/academicsurvey_devops_practices_and_software/,False,False,False,False
1lmdw0p,Semantic layer vs Semantic model,2,3,PresentationTop7288,"Hello guys, I am having a difficulty finding out the definition of what exactly semantic layer and semantic model is? 
My understanding is semantic layer is just business friendly names of tables from database just like a catalog. And semantic model is building relationships measures with business friendly table and field names. Different AI tools telling different definitions. I am confused. Can someone explain me
1. What is semantic layer?
2. What is semantic model?
3. Which comes first?
4. Where can I build these two? ( I mean tools ) 

",2025-06-28 04:19:13,https://www.reddit.com/r/dataengineering/comments/1lmdw0p/semantic_layer_vs_semantic_model/,False,False,False,False
1llvv2d,End to End Data Engineering Project | What is Data Engineering ? | Part 1,1,0,Beneficial-Buyer-569,,2025-06-27 14:51:55,https://youtube.com/watch?v=FToSFSVz9WM&si=tqNxT6FCauNxntQS,False,False,False,False
1llvs04,Biggest Pains in Current Tooling?,1,14,AMDataLake,"Curious what tools are you using, what are the biggest pains you currently experience with them (and primary value you get).",2025-06-27 14:48:31,https://www.reddit.com/r/dataengineering/comments/1llvs04/biggest_pains_in_current_tooling/,False,False,False,False
1llu6yc,Turning DBT snapshots into SCD2 Silver tables,1,8,Mike8219,"I have started capturing company wide data in SCDs with DBT snapshots. I want to turn these into silver dim and fact models but I need to retain all changes in the snapshots from and thru timestamps.

I wrote a DBT macro that joins any table needed for a query together and sorts out the from and thrus but it feels clunky. It feels like the wrong solution. What's the best way you have found to join many SCDs into one SCD while capturing the start and and timestamps all of the changes in every table involved? ",2025-06-27 13:41:25,https://www.reddit.com/r/dataengineering/comments/1llu6yc/turning_dbt_snapshots_into_scd2_silver_tables/,False,False,False,False
1lllraf,I built a multimodal document workflow system using VLMs - processes complex docs end-to-end,1,1,yes-no-maybe_idk,"Hey r/dataengineering 

We're building Morphik: a multimodal search layer for AI applications that works super well with complex documents.

Our users kept using our search API in creative ways to build document workflows and we realized they needed proper workflow automation, not just search queries.

So we built workflow automation for documents. Extract data, save to metadata, add custom logic: all automated. Uses vision language models for accuracy.

We use it for our invoicing workflow - automatically processes vendor invoices, extracts key data, flags issues, saves everything searchable.

Works for any document type where you need automated processing + searchability. (an example of it working for safety data sheets below)

We'll be adding remote API calls soon so you can trigger notifications, approvals, etc.

Try it out: [https://morphik.ai](https://morphik.ai)

GitHub: [https://github.com/morphik-org/morphik-core](https://github.com/morphik-org/morphik-core)

Would love any feedback/ feature requests!

https://reddit.com/link/1lllraf/video/ix62t4lame9f1/player

",2025-06-27 05:17:45,https://www.reddit.com/r/dataengineering/comments/1lllraf/i_built_a_multimodal_document_workflow_system/,False,False,False,False
1lme7zn,What to learn first ? stuck on lots of different technologies,0,3,erickedrm,"Hi, just overwhelmed with all the stack to become a DE (or similar role), and land an entry job.

I have a background in tech, also have a CS degree ( Mexico btw, not sure if it helps a lot)

I do know Python (basic and POO stuff) also Java and Angular (main stack) ,but currently im working with SIEBEL( Oracle CRM) and i think im getting stuck in this tech and i want a change, i think it helps that i use a lot of SQL (not for big data)

I know the very basics of Python for analysis 

I took a course for PowerBi (not sure if needed but hope it does)and im thinkin to learn spark next, but theres a lot of things that im missing, such a data warehouses or cloud.

But i think im a bit lost about the ""path"" i should follow , i know its hard  to start as a DE or similar but i want to be as prepared as i can be for future interviews.

So any tips are welcomed, tips for interviews aswell

Thank you.

",2025-06-28 04:38:49,https://www.reddit.com/r/dataengineering/comments/1lme7zn/what_to_learn_first_stuck_on_lots_of_different/,False,False,False,False
1lmd9m4,dbt Cloud w/o deployments?,0,0,yeykawb,"In a project where we use dbt Cloud but really we are missing out on a bunch of stuff included in the platform. 

We deploy the dbt project with Azure DevOps, not the built-in deployments or Slim CI. The project gets uploaded to Databricks and we orchestrate everything from there.

Now, by doing this, we don‚Äôt make use of the environments in dbt Cloud and not even the docs page/explore at all. Our builds require full parse each time as we don‚Äôt have the manifest. We can‚Äôt defer.

The infra was set up by another company so I‚Äôm not sure if there are any pros that I have missed, of if there are cons that they missed by doing it this way?

I could also mention we have 4 repos in total and all of them run cicd in ADO, if ‚Äùkeep everything in one place‚Äù would be an argument.",2025-06-28 03:43:56,https://www.reddit.com/r/dataengineering/comments/1lmd9m4/dbt_cloud_wo_deployments/,False,False,False,False
1lm3ogl,What do you use for schema evolution in the data lake?,0,1,Then_Crow6380,"Handling of changing data types in the source data is a challenge. Next, I'll explore variant types once we migrate to Spark 4.",2025-06-27 20:05:47,https://www.reddit.com/r/dataengineering/comments/1lm3ogl/what_do_you_use_for_schema_evolution_in_the_data/,False,False,False,False
1llq8jw,SQLite questions,0,3,Thalissa_,"Hello everyone, I have a question, 
How can I to do conection with SQLite for SQL server? 
I tried to do conection with ODBC, but doesn't works.
",2025-06-27 10:13:27,https://www.reddit.com/r/dataengineering/comments/1llq8jw/sqlite_questions/,False,False,False,False
